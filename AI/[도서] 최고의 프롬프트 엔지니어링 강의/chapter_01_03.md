> 이 글은 `최고의 프롬프트 엔지니어링 강의` 도서를 읽고 요약 정리한 글입니다.

# Part 1. 머신러닝과 딥러닝의 개념

- AI는 크게 `규칙 기반 AI` 와 `머신러닝` 두 가지로 구분할 수 있다.
  - **규칙 기반 AI**: 길다, 노란색이다, 약간 휘었다 등의 특징을 가진 물체가 바나나라는 것을 사람이 AI에게 먼저 알려줌
  - **머신 러닝**: 사람이 일단 바나나 사진을 AI에게 보여주고 이게 바나나임을 알려줌. 그럼 AI가 스스로 이를 분석하여 길다, 노랗다, 약간 휘었다 등의 특징을 직접 추출하고 기억함
- `레이블링(labeling)`: 사람이 바바나임을 알려주는 것
- `지도 학습(Supervised Learning)`: AI가 레이블링한 데이터를 학습하는 것
- `비지도 학습(Unsupervised Learning)`: AI가 먼저 특징을 파악하게 하는 방식. 어떤 것들은 길고 노란색이고, 어떤 것들은 하얗고 납작하고 둥글하다는 것을 AI가 인식한 후에 사람이 "이 것은 바나나야"라고 알려주는 것.

## 전통적인 머신러닝과 딥러닝의 차이점

딥러닝은 머신러닝의 일종이지만 약간 다른 지점이 있다.

먼저 **딥러닝**이란, 인공 신경망을 학습시키는 방법으로, 사람의 뇌 작동 방식을 모방해서 만든 기술이다. 정확하게 뇌 기능을 그대로 구현한 것은 아니고 뇌에서 힌트를 얻어 만든 것이다.
사람의 뇌는 뉴런을 통해 신호를 보내고 받아, 이러한 신호들을 여러 뉴런에 걸쳐 연결해 기능한다. 인공 신경망도 마찬가지로 앞에서 `입력값(X)`을 가져오면 거기에 `가중치(W)`를 곱한 값을 `출력(Y)`해 다양한 방법으로 계속 연결한다.  
컴퓨터에 어떤 사진이나 문자를 입력하면 컴퓨터가 이것을 다시 수많은 숫자들로 바꾼 뒤(입력), 각 숫자에 특정한 수학적 변형을 적용하고(가중치, 편향, 활성화 함수), 이를 바탕으로 최종 결정(출력)을 내리는 방식으로 작동합니다. 그리고 이 과정을 여러 번 거친 결과를 토대로 최종 결과를 도출한다.

- **신선한 바나나 찾기 예제**
여러 바나나 사진을 입력값으로 넣고, 입력값에 다양한 가중치를 곱하면서 그중 출력값이 `신선한 바나나`로 나오는 가중치를 찾는다. 여기서 가중치란 `바나나는 어떻다`라고 설명하는 특징으로 표현할 수 있다. 예를 들어 `신선도`를 나타내는 조건이 다음과 같다면, `신선한 바나나`의 척도가 되는 조건에는 높은 가중치, 그렇지 않은 조건에는 낮은 가중치를 적용하는 것이다.
  - **색상**: 노란색, 녹색, 갈색
  - **질감**: 매끄럽다, 주름이 있다, 탄력이 있다, 탄력이 없다
  - **반점의 유무**: 반점이 있다, 반점이 없다, 반점이 작다, 반점이 많다, 반점이 크다, 반점이 적다

이렇게 신선한 바나나를 구별할 수 있도록 학습한 후에는 다른 바나나 사진을 입력해도 가중치를 곱했을 때 `신선한 바나나`라고 정확하게 예측할 수 있는 것이다.

그렇다면 전통적인 머신러닝은 딥러닝과 어떤 차이점이 있는가?
**전통적인 머신러닝**의 경우, 모델에 데이터를 입력하기 전에 사람이 먼저 입력할 데이터를 변환하거나 추출하는 피처 엔지니어링 과정이 많이 필요함. 여기서 말하는 피처는 쉽게 말해 데이터의 특성이나 속성을 말하며 바나나의 경우 크기, 색상, 원산지, 숙성 정도 등을 의미한다.
모든 피처가 모델에 유용한 것은 아니기 때문에, 우리가 해결해야 할 문제를 머신 러닝 모델이 더 잘 이해하고 예측할 수 있도록 **사람이 개입해 피처를 선별하고 가공 및 조합하여 수많은 데이터를 만들어내야한다.**  
반면 **딥러닝**의 경우 사람이 개입하는 과정이 머신러닝에 비해 훨씬 적다. 물론 딥러닝이 전통적인 머신러닝 모델과 비교했을 때 피처 엔지니어링이나 알고리즘을 만드는 과정이 상대적으로 덜 필요한 것이리 뿐 전혀 필요하지 않은 것은 아님. 다만 심층 신경망이 원시 데이터에서 복잡한 패턴과 관계를 스스로 학습할 수 있는 능력을 가지고 있기 때문에 전통적인 머신러닝에 비해서는 극도로 줄어듬.

즉, 딥러닝은 피처 엔지니어링을 최소호하면서 극도로 많은 데이터를 기반으로 AI 모델을 만드는 방법을 사용할 수 있는 기술이다.

# LLM, 완전히 새로운 시대의 개막

- **긴 맥락의 이해를 가능하게 한 트랜스포머**
  - 구글에서 개발한 인공 신경망 구조인 트랜스포머는 훗날 BERT와 GPT를 만든 기반 기술
  - 트랜스포머의 어텐션 메커니즘이 가진 학습 능력은 생성 가능한 텍스트 길이의 제한을 대폭 개선하고 처리 속도를 크게 향상시켰으며, 양방향 문맥 이해로 주어진 단어의 의미를 전체 문장의 맥락에서 파악하는 것까지 가능하게 함
  - 셀프 어텐션 메커니즘이란 문장 내 단어들 간의 관계를 학습하여 중요한 정보에 더 많은 가중치를 두고 집중하도록 만드는 기술로, 이 능력으로 인해 자연어 처리 성능이 크게 향상되어 LLM의 발전에 중요한 이정표가 됨.
- **ChatGPT**
  - **인스트럭트 데이터**란 지시와 결과의 쌍으로 되어 있는 데이터로, 이를 학습시켜 사용자가 제공하는 지시에 더 잘 응답하도록 최적화하는 것
  - **RLHF(Reinforement Learning from Human Feedback)** 은 GPT-3가 만들어 낸 결과를 사람이 평가하게 한 다음, 그 평가 점수와 수정된 내용을 기반으로 스스로가 다시 학습하도록 한 방식
- **LLM의 작동 원리**
  - GPT와 같은 모델을 `자기회귀 모델`이라고 부름
    - `아버지가 방에 들어가신다`라는 문장에서 `아버지가`와 `방에`라는 두 개의 시퀀스를 주면 모델은 `들어가신다`라는 다음 단어를 예측함
    - 이전 결과를 바탕으로 다음 단어 예측을 반복하는 것을 자기회귀 방식이라고 하며 이것이 바로 LLM의 작동 원리임
- **LLM 성능을 향상시킨 주요 기술**
  - **코드 데이터 학습**: LLM으로 사용자에게 유용한 기능을 제공하려면 비정형 데이터에서 정형 데이터로, 그리고 정형 데이터에서 비정형 데이터로 변환할 수 있는 능력이 중요함
    - `정형 데이터`: 주소록이나 회원 정보와 같이 특정 형식이나 구조를 가진 데이터를 말함
    - `비정형 데이터`: 소셜 미디어 게시글, 이메일 본문, 프로그램 코드 등 정해진 형식이나 구조가 없는 데이터
  - **인스트럭션 튜닝**: 명령이나 지시 형태로 표현된 텍스트를 이해한 뒤 해당 작업을 수행하는 것
    - 대량의 텍스트를 학습한 기본 모델을 만든 후 지시와 결과물의 쌍으로 된 인스트럭트 데이터를 학습시켜 튜닝시킴.
    - 이전에는 모델이 앞에 있는 텍스트를 연결해서 뒤에 올 텍스트를 유추하는 정도였지만, 인스트럭션 튜닝을 통해 모델이 사람의 명령을 이해하고 그에 맞는 텍스트를 생성하는 방식이 가능해짐
  - **RLHF**: GPT가 생성한 결과를 사람이 평가해서 점수를 주거나 결과를 수정하고, 이후 사람이 평가한 내용을 바탕으로 스스로 다시 학습하도록 만드는 기술. 이 기술로 GPT는 사용자의 질문이나 지시에 더 적절하게 반응할 뿐만 아니라 비윤리적이나 부적절한 내용을 피하는 등의 윤리적 가이드라인을 더 잘 준수하게 됨.
    - 먼저 다양한 요청이나 명령을 담은 `프롬프트 데이터셋`에서 여러 프롬프트 샘플을 추출함.
    - 이 샘플은 `초기 언어 모델`에 입력되어 프롬프트와 관련된 텍스트를 생성.
    - 생성된 텍스트는 사람에 의해 평가되며, 각각의 텍스트는 품질에 따라 점수를 받음.
    - 앞서 언어 모델이 생성한 텍스트가 어떤 것이 더 좋은지를 판단할 수 있는 기준을 제공
  - **멀티모달**: 이미지와 소리, 텍스트 등과 같이 서로 다른 형태의 데이터를 동시에 학습시킴으로써 LLM이 더 풍부한 이해 능력을 갖게 함
    - 고양이 사진을 보고 표정을 설명한다거나 우는 아이 사진을 보고 왜 우는 지를 설명하는 것과 같이, 이미지 분석 결과를 토대로 텍스트 형태의 질문에 답변하는 방식을 학습함.
    - 컴퓨터는 이미지 속 객체를 인식하고 상황이나 감정, 장면에 표시된 문구 등을 이해할 수 있음.
- 빅 모델 사용 시, 파인튜닝과 프롬프트 엔지니어링 간의 성능 차이가 매우 크지 않다.
  - 이 말이 프롬프트 엔지니어링으로 모두 대체할 수 있다는 것은 아님. 다음과 같이 모델링이나 파인튜닝이 필요한 경우는 계속해서 존재할 것임
    - 숫자를 예측하는 선형 회귀 문제
    - 대량의 로그성 데이터의 실시간 처리
    - 특수 목적의 매우 높은 정밀도를 요구하는 문제
    - 데이터의 최신성이 중요하지 않은 경우
    - 데이터 보안이 매우 중요한 경우
