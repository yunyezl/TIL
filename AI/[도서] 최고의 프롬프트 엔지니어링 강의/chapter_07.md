# Chapter 7. LLM 구성 요소 및 생성 조건

LLM을 구성하는 데에는 여러가지 중요한 조건과 구성 요소가 있다. 이러한 조건들은 모델의 성능, 범용성, 그리고 실용성에 직접적인 영향을 끼치는 것들로, GPT 뿐만 아니라 거의 대부분의 LLM에 통용되는 옵션이다.

## 토큰

**토큰**이란 언어 모델에 입력하거나 출력하는 텍스트의 구성 요소를 의미한다. 예를 들어 `apple`이라는 단어와 관련된 토큰은 다양하게 나올 수 있다. 같은 `apple`이라는 단어가 포함되어 있다고 해도 단수형인 `apple`단어 하나만 있을 때는 token 1개, `apples`는 `app`과 `les`로 나눠져서 토큰 2개, `I love apple.`은 띄어쓰기와 마침표까지 포함해서 토큰 4개로 앞뒤 텍스트 종류에 따라 다양한 조각들로 분리될 수 있다.

왜 이렇게 토큰 개수가 달라질까? 이는 토큰이 단어 단위가 아니라 텍스트를 구성하는 요소들로 이루어지기 때문이다. 띄어쓰기가 포함된 것이 토큰이기도 하고, apples라는 단어를 쪼개서 app과 les 두 가지가 토큰이 되기도 한다. 그리고 각 단어들이 실제로 LLM 모델에 들어갈 때는 알파벳이나 문자 그대로가 아니라 각 토큰이 가지고 있는 고유 번호 형태로 들어간다. 예를 들어 `I Love apple.`이라는 문장에 있는 토큰들을 고유 번호로 변환하면 `[40, 1842, 17180, 13]`과 같은 숫자 형태가 나온다.

이와 같이 토큰을 분리하는 방법은 여러 가지가 있지만, 일반적으로 **BPE** 방법을 많이 사용한다. 이는 가장 많이 나타나는 문자열 쌍을 합치는 방식으로, 문장 혹은 단어 안에 있는 글자들을 적절한 단위로 나눈 다음 빈도가 높은 글자 조합을 토큰으로 사용한다.

한국어, 중국어, 일본어 등은 영어보다 더 많은 토큰을 사용한다. 물론 모든 모델이 그런 것은 아니며, LLM마다 각각 다른 토크나이저를 사용하기 때문에 토큰이 어떻게 쪼개지는지를 정확하게 알고 싶다면 각 모델에 맞는 토크나이저로 확인할 필요가 있다.

대다수의 LLM은 아직 한글 토큰 사용이 상당히 비효율적이므로 다음과 같은 전략으로 토큰 사용을 최적화할 필요가 있다.

1. **프롬프트를 영어로 작성한다.**
프롬프트 입력과 출력을 모두 영어로 작성하면 사용하는 토큰의 수를 줄일 수 있고, 더불어 출력 품질이나 추론 성능이 향상되는 효과도 있다.
2. **입출력하기 전에 먼저 번역하여 사용한다.**
프롬프트에 포함시킬 컨텍스트를 영어로 번역하여 사용하고, 영어로 출력된 내용을 다시 한글로 번역한다. 이 방법은 번역 품질과 번역 비용 및 속도도 함께 고려해야 하기 때문에 꼭 필요할 때만 사용한다.

## 컨텍스트 윈도우

**컨텍스트 윈도우**란 문맥을 판단하거나 다음 단어를 예측하기 위해 참고할 토큰의 범위 또는 언어 모델이 다룰 수 있는 최대 토큰 수를 가리킨다.

다음은 컨텍스트 윈도우가 5개 인 경우다.
> [The] [quick] [brown] [fox] [jumps] over
> The [quick] [brown] [fox] [jumps] [over] the

첫 번째 문장에서 over라는 단어를 예측하기 위해 앞에 있는 `The`, `quick`, `brwon`, `fox`, `jumps`라는 5개의 단어를 참고한다. 그 다음 `over`의 다음 단어인 `the`를 예측하기 위해 앞에 있는 5개의 단어를 참고한다.

여기서 다음 단어를 예측하기 위해 참고하는 앞의 단어 5개를 컨텍스트 윈도우라고 말한다. 보통은 단어가 아니라 토큰 수를 사용하기 때문에 토큰 윈도우라고도 한다. 즉, 이 컨텍스트 윈도우의 크기가 크면 클수록 더 길고 복잡한 문서를 이해할 수 있다는 이야기이다.

## 주요 생성 옵션

LLM 모델의 예측 가능성을 조절하는 주요 생성 옵션들이 있다. 여기서 소개하는 것은 총 일곱 가지이며, 가장 많이 사용하는 것은 `Temperature`와 `Maximum length` 정도이다.

### Temperature

**Temperature**는 **출력할 토큰 후보 중 얼마나 높은 확률의 토큰을 사용할지 선택하는 옵션**이다. 텍스트 생성 시 모델이 얼마나 창의적인 결과를 생성할지를 결정짓는 요소 중 하나로, 일반적으로 0~1 사이의 실수로 설정된다. 예를 들어 0.8과 같이 높은 값은 최종적으로 선택할 단어의 범위를 넓혀 다양한 답변을 생성하게 하고, 0.2와 같이 낮은 값은 다음 단어를 출현 확률이 높은 단어에 집중시키도록 만든다. 따라서 값이 높을수록 더욱 창의적인(무작위적이고 환각이 많은) 답변을 하고, 값이 낮을수록 일관된 답변을 한다고 생각하면 쉽다.

Bing Chat의 경우 답하는 옵션을 `창의적인 것`과 `정확한 것`의 두 개로 나눌 수 있다. 이 두가지 옵션은 Temperature을 구분해놓은 것과 같다.

### Top P, Top K

Temperature는 여러 후보군 중에 출력할 토큰을 선택하는 옵션이고, **Top P**와 **Top K**는 출력할 토큰의 후보를 선택하는 옵션이다. Top P는 확률이 상위 P%인 토큰을, Top K는 확률이 상위 K개인 토큰의 결과를 출력 후보로 선택한다. 일반적으로는 주로 Temperature만 변경하지만, Temperature를 매우 높게 하면 생성된 문장이 맥락을 크게 벗어나거나 잘못된 글자를 출력할 수도 있으므로 이를 방지하기 위해 추가로 사용한다.

예를 들어 Top K를 3개로 설정했다고 하면, 이 경우 컨텍스트로 준 텍스트에서 생성할 수 있는 여러 가지 후보군 중 가장 확률이 높은 3개의 후보를 선택한다. 그리고 Temperature가 낮으면 (0.1부터 0.3) 셋 중 가장 높은 확률의 토큰을 확정해서 출력하고, Temperature가 높으면(0.7부터 1) 셋 중 하나를 랜덤으로 출력한다.

Top P는 Top K와 달리 상위 2개, 상위 3개 식으로 선택하는 것이 아니라 생성 결과로 만들어질 수 있는 토큰 중 상위 특정 퍼센트에 해당하는 토큰들만 후보군으로 선택한다. 예를 들어 Top P가 0.7이면 다음과 같이 전체 5개 중 누적 합산으로 70%에 해당하는 2개를 선택해서 후보군으로 만드는 것이다.

### Maximum Length

**Maximum Length(최대 길이)** 는 생성할 최대 토큰 수를 설정하는 것이다. 입력한 토큰(프롬프트)와 최대 토큰 수가 모델의 최대 토큰 수를 넘지 않도록 주의 깊게 설정해야 한다.

### Frequency Penalty

**Frequency Penalty(빈도 패널티)** 는 출력에서 같은 토큰이 반복되면 패널티를 부여하는 파라미터다. 이 파라미터의 값이 높을수록 모델은 같은 단어나 표현을 반복해서 사용하는 것을 지양한다. 예를 들어 "이 멋진 글은 멋진 글이네요."와 같은 문장 대신 "이 멋진 글은 훌륭한 문장이네요."와 같이 생성하도록 유도한다.

### Presence Penalty

**Persence Penalty(존재 패널티)** 는 특정 토큰이 이미 한 번 이상 출력된 상황에서 토큰을 다시 사용하려 할 때 부여되는 패널티이다. Freqeuncy Penalty가 특정 토큰의 반복 빈도에 패널티를 부여한다면 Presence Penalty는 토큰이 최소 한 번 이상 등장했는지의 여부에 따라 패널티를 부여하는 방식이다.

이 옵션을 잘 사용하면 생성된 텍스트가 다양한 토큰을 포함하도록 유도하여 폭넓은 아이디어와 주제 탐색이 가능해진다. 그렇다고 너무 높게 설정하면 생성 결과의 일관성을 유지하기 어려워질 수 있으니 사용하는 데 주의가 필요하다.

### Stop Sequence

**Stop Sequence(중단 시퀀스)** 는 특정 문구를 설정한 다음 해당 문구가 나오면 답변 생성을 중지하는 옵션이다. LLM이 무의미하게 생성을 반복하는 경우를 제어하거나 반복적인 시퀀스의 생성을 유도할 때 사용한다. 그러나 요즘은 LLM의 성능이 좋아져 무의미하게 생성을 반복하는 경우가 많이 줄었고, 따라서 이 옵션은 현재 많이 사용하지 않는 편이다.

### Injection Start

**Injection Start(시작 문구 주입)** 은  Stop Sequence와는 반대되는 개념으로, 생성을 시작하기 전에 특정한 문구를 먼저 삽입하는 것을 말한다. 이는 다음 생성 결과를 원하는 대로 유도할 수 있다는 장점이 있다.

예를 들어 사용자가 `안녕?`이라고 질문하고 어시스턴트의 답변을 원했지만 어시스턴트는 사용자의 인사를 마저 완성하라는 의도로 잘못 이해해 답변 대신 인사의 다음 단어를 생성하려는 경우가 있다. 이때는 결과를 원하는 대로 유도하기 위해 `Assistant:`를 Injection Start로 등록하면 답변을 생성하기 전에 `Assistant:`를 추가하여 의도에 맞는 답변을 생성할 수 있다.